{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP4K+6eNR+WMaZPsH2RZuaW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulinaPacyna/DL_speech_recognition/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkqHae_Gj-gY"
      },
      "source": [
        "You can use this code in your notebook to load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vpW_mNnxq6d"
      },
      "source": [
        "import librosa\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Activation, BatchNormalization\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "if not os.path.isdir('train'):\n",
        "  !pip install kaggle\n",
        "  !pip install py7zr\n",
        "  import py7zr\n",
        "  !mkdir /root/.kaggle\n",
        "  !touch /root/.kaggle/kaggle.json\n",
        "\n",
        "  api_token = {\"username\":\"paulinapacyna\",\"key\":\"31e4c572f1ddefc96883c2195f33726b\"}\n",
        "  # please don't hold it against me xD\n",
        "\n",
        "  with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "      json.dump(api_token, file)\n",
        "\n",
        "  !chmod 600 /root/.kaggle/kaggle.json\n",
        "  !kaggle config path -p /root\n",
        "  !kaggle competitions download -c tensorflow-speech-recognition-challenge\n",
        "  with py7zr.SevenZipFile('train.7z', mode='r') as z:\n",
        "      z.extractall()\n",
        "  # with py7zr.SevenZipFile('test.7z', mode='r') as z:\n",
        "  #     z.extractall()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-LNwcsPh_Gk",
        "outputId": "75cb1e0d-4d4c-4a3b-a814-2c4fa9510bc4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "DcrkhkGM2alZ",
        "outputId": "74df9ee8-5fc5-4920-d986-f0e5cc5ea80a"
      },
      "source": [
        "paths = [os.path.join(dp, f) for dp, dn, fn in os.walk('train/audio') for f in fn if f[-4:]=='.wav']\n",
        "paths = pd.DataFrame(paths, columns=['path']) # .sample(n=1000).reset_index(drop=True)\n",
        "paths['label'] = paths['path'].apply(lambda x: x.split('/')[-2])\n",
        "paths"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/audio/five/1a073312_nohash_0.wav</td>\n",
              "      <td>five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/audio/five/c93d5e22_nohash_0.wav</td>\n",
              "      <td>five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/audio/five/57cb3575_nohash_0.wav</td>\n",
              "      <td>five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/audio/five/b5552931_nohash_0.wav</td>\n",
              "      <td>five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/audio/five/187af8be_nohash_0.wav</td>\n",
              "      <td>five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64722</th>\n",
              "      <td>train/audio/on/d90b4138_nohash_0.wav</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64723</th>\n",
              "      <td>train/audio/on/471a0925_nohash_0.wav</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64724</th>\n",
              "      <td>train/audio/on/9d050657_nohash_0.wav</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64725</th>\n",
              "      <td>train/audio/on/d0f7bef5_nohash_0.wav</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64726</th>\n",
              "      <td>train/audio/on/49af4432_nohash_2.wav</td>\n",
              "      <td>on</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64727 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         path label\n",
              "0      train/audio/five/1a073312_nohash_0.wav  five\n",
              "1      train/audio/five/c93d5e22_nohash_0.wav  five\n",
              "2      train/audio/five/57cb3575_nohash_0.wav  five\n",
              "3      train/audio/five/b5552931_nohash_0.wav  five\n",
              "4      train/audio/five/187af8be_nohash_0.wav  five\n",
              "...                                       ...   ...\n",
              "64722    train/audio/on/d90b4138_nohash_0.wav    on\n",
              "64723    train/audio/on/471a0925_nohash_0.wav    on\n",
              "64724    train/audio/on/9d050657_nohash_0.wav    on\n",
              "64725    train/audio/on/d0f7bef5_nohash_0.wav    on\n",
              "64726    train/audio/on/49af4432_nohash_2.wav    on\n",
              "\n",
              "[64727 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzcgKegP_5j6"
      },
      "source": [
        "def audio2mel(path):\n",
        "    y, sr = librosa.core.load(path=path)\n",
        "    if len(y) > sr: # we set all to have lenght equal to 1 second \n",
        "        y = y[:sr] \n",
        "    else: # pad blank\n",
        "        padding = sr - len(y)\n",
        "        offset = padding // 2 \n",
        "        y = np.pad(y, (offset, sr - len(y) - offset), 'constant')\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "    return librosa.power_to_db(mel, ref= np.max).astype(np.float) \n",
        "\n",
        "def convert_wav_to_image(df):\n",
        "    X = []\n",
        "    for _,row in tqdm(df.iterrows(), total = df.shape[0]):\n",
        "        x = audio2mel(row['path'])\n",
        "        X.append(x.transpose())\n",
        "    X = np.array(X) \n",
        "    return X\n",
        "os.chdir('/content/drive/MyDrive/DL3/')\n",
        "if os.path.exists('X_train.npy') and os.path.exists('y_train.npy') and os.path.exists('class_names.npy'):\n",
        "  X = np.load('X_train.npy', allow_pickle=True)\n",
        "  y = np.load('y_train.npy', allow_pickle=True)\n",
        "  classess = np.load('class_names.npy', allow_pickle=True)\n",
        "else:\n",
        "  X = convert_wav_to_image(paths)\n",
        "  enc = OneHotEncoder() \n",
        "  y = enc.fit_transform(paths[['label']]).todense()\n",
        "  classes = enc.get_feature_names()\n",
        "  np.save('X_train.npy', X)\n",
        "  np.save('y_train.npy', y)\n",
        "  np.save('class_names.npy', classes)\n",
        "X = (X - np.mean(X))/np.std(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry6XoeYze7bT"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization())\n",
        "model.add(LSTM(\n",
        "    256,\n",
        "    input_shape=X.shape[1:],\n",
        "    return_sequences=True\n",
        "))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(y.shape[1]))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8BYv0IqiaoO",
        "outputId": "915dae6a-231c-4ca9-d8f1-fb4e493cf7e2"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=100, epochs=10, validation_split=0.3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "304/304 [==============================] - 32s 39ms/step - loss: 2.0171 - val_loss: 0.7370\n",
            "Epoch 2/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.6414 - val_loss: 0.4667\n",
            "Epoch 3/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.4228 - val_loss: 0.3860\n",
            "Epoch 4/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.3342 - val_loss: 0.3777\n",
            "Epoch 5/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.2633 - val_loss: 0.3592\n",
            "Epoch 6/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.2329 - val_loss: 0.3164\n",
            "Epoch 7/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.2046 - val_loss: 0.3005\n",
            "Epoch 8/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.1698 - val_loss: 0.2920\n",
            "Epoch 9/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.1638 - val_loss: 0.2761\n",
            "Epoch 10/10\n",
            "304/304 [==============================] - 10s 33ms/step - loss: 0.1379 - val_loss: 0.2984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2920df390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLJJdlt-lXxW",
        "outputId": "76d4ba81-4fa5-4348-ff5d-109d58179e57"
      },
      "source": [
        "p = model.predict(X_test)\n",
        "np.mean(np.argmax(p,1) == np.argmax(y_test,1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.922191011235955"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}